{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# Unified Financial Statement Data Retriever\n",
                "This notebook unifies the process of extracting data from financial statements (PDFs) using either OCR or Direct extraction methods, followed by LLM-based parsing and Excel conversion."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import io\n",
                "import json\n",
                "import re\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "from pypdf import PdfReader\n",
                "import pytesseract\n",
                "from PIL import Image\n",
                "from langchain_google_genai import ChatGoogleGenerativeAI\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_core.output_parsers import StrOutputParser"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "config_header",
            "metadata": {},
            "source": [
                "## 1. Configuration and User Input"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "id": "config",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Configured for: pypdf\n",
                        "Periods: ['2020', '2021', '2022', '2023', '2024']\n",
                        "Method: PYPDF\n",
                        "Page range: 60-140\n"
                    ]
                }
            ],
            "source": [
                "# --- User Input ---\n",
                "company_folder_name = input(\"Enter the company folder name (e.g., PVIAM): \").strip()\n",
                "periods_input = input(\"Enter periods to process (e.g., 2021, 2022): \")\n",
                "periods_to_process = [p.strip() for p in periods_input.split(',') if p.strip()]\n",
                "\n",
                "extraction_method = \"\"\n",
                "while extraction_method not in [\"ocr\", \"pypdf\"]:\n",
                "    extraction_method = input(\"Choose extraction method (ocr / pypdf): \").strip().lower()\n",
                "\n",
                "page_range_input = input(\"Enter page range (e.g., 50-90, leave blank for all): \").strip()\n",
                "start_page, end_page = None, None\n",
                "if page_range_input and '-' in page_range_input:\n",
                "    try:\n",
                "        s, e = page_range_input.split('-')\n",
                "        start_page, end_page = int(s), int(e)\n",
                "    except ValueError:\n",
                "        print(\"Invalid range format. Processing all pages.\")\n",
                "\n",
                "# --- Paths ---\n",
                "# Updated to use the correct workspace root\n",
                "base_workspace = Path(r\"D:\\Visual Studio Projects\\Financial Statement Data Retriever\")\n",
                "company_base_path = base_workspace / company_folder_name\n",
                "base_pdf_dir = company_base_path / \"financial_statements\"\n",
                "text_dir = company_base_path / \"text_statements\"\n",
                "json_dir = company_base_path / \"json_statements\"\n",
                "excel_dir = company_base_path / \"excel_statements\"\n",
                "\n",
                "for d in [text_dir, json_dir, excel_dir]:\n",
                "    d.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(f\"\\nConfigured for: {company_folder_name}\")\n",
                "print(f\"Periods: {periods_to_process}\")\n",
                "print(f\"Method: {extraction_method.upper()}\")\n",
                "if start_page:\n",
                "    print(f\"Page range: {start_page}-{end_page}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "extraction_header",
            "metadata": {},
            "source": [
                "## 2. PDF to Text Extraction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "id": "extraction_logic",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Starting PDF Text Extraction ---\n",
                        "Skipping 2020: File not found at D:\\Visual Studio Projects\\Financial Statement Data Retriever\\pypdf\\financial_statements\\2020.pdf\n",
                        "Skipping 2021: File not found at D:\\Visual Studio Projects\\Financial Statement Data Retriever\\pypdf\\financial_statements\\2021.pdf\n",
                        "Skipping 2022: File not found at D:\\Visual Studio Projects\\Financial Statement Data Retriever\\pypdf\\financial_statements\\2022.pdf\n",
                        "Skipping 2023: File not found at D:\\Visual Studio Projects\\Financial Statement Data Retriever\\pypdf\\financial_statements\\2023.pdf\n",
                        "Skipping 2024: File not found at D:\\Visual Studio Projects\\Financial Statement Data Retriever\\pypdf\\financial_statements\\2024.pdf\n"
                    ]
                }
            ],
            "source": [
                "def extract_text_from_pdf(pdf_path, method, start_page=None, end_page=None):\n",
                "    text_content = []\n",
                "    \n",
                "    if method == \"pypdf\":\n",
                "        reader = PdfReader(pdf_path)\n",
                "        total_pages = len(reader.pages)\n",
                "        pages_to_extract = range(total_pages)\n",
                "        if start_page and end_page:\n",
                "            pages_to_extract = range(max(0, start_page - 1), min(total_pages, end_page))\n",
                "            \n",
                "        for i in pages_to_extract:\n",
                "            page = reader.pages[i]\n",
                "            text = page.extract_text()\n",
                "            text_content.append(f\"--- PAGE {i+1} ---\\n{text}\\n\")\n",
                "            \n",
                "    else: # fitz or ocr\n",
                "        doc = fitz.open(pdf_path)\n",
                "        total_pages = len(doc)\n",
                "        pages_to_extract = range(total_pages)\n",
                "        if start_page and end_page:\n",
                "            pages_to_extract = range(max(0, start_page - 1), min(total_pages, end_page))\n",
                "\n",
                "        for i in pages_to_extract:\n",
                "            page = doc.load_page(i)\n",
                "            if method == \"ocr\":\n",
                "                pix = page.get_pixmap(dpi=300) # Balanced DPI\n",
                "                img_bytes = pix.tobytes(\"png\")\n",
                "                img = Image.open(io.BytesIO(img_bytes))\n",
                "                text = pytesseract.image_to_string(img, lang=\"vie+eng\", config=\"--psm 3\")\n",
                "            else: # direct fitz\n",
                "                text = page.get_text(\"text\")\n",
                "            \n",
                "            text_content.append(f\"--- PAGE {i+1} ---\\n{text}\\n\")\n",
                "        doc.close()\n",
                "        \n",
                "    return \"\\n\".join(text_content)\n",
                "\n",
                "print(\"--- Starting PDF Text Extraction ---\")\n",
                "for period in periods_to_process:\n",
                "    pdf_path = base_pdf_dir / f\"{period}.pdf\"\n",
                "    out_txt = text_dir / f\"{period}_{extraction_method}.txt\"\n",
                "    \n",
                "    if not pdf_path.exists():\n",
                "        print(f\"Skipping {period}: File not found at {pdf_path}\")\n",
                "        continue\n",
                "        \n",
                "    print(f\"Processing {period} via {extraction_method.upper()}...\")\n",
                "    try:\n",
                "        extracted_text = extract_text_from_pdf(pdf_path, extraction_method, start_page, end_page)\n",
                "        with out_txt.open(\"w\", encoding=\"utf-8\") as f:\n",
                "            f.write(extracted_text)\n",
                "        print(f\"Saved to: {out_txt.name}\")\n",
                "    except Exception as e:\n",
                "        print(f\"Error processing {period}: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "llm_header",
            "metadata": {},
            "source": [
                "## 3. LLM Data Extraction (Gemini)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "llm_logic",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "<>:8: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
                        "<>:8: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
                        "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_11036\\3975901367.py:8: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
                        "  (\"system\", \"You are an expert financial analyst. Your task is to extract various line items and their values from the provided text. \"\n"
                    ]
                },
                {
                    "ename": "TypeError",
                    "evalue": "'tuple' object is not callable",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mGOOGLE_API_KEY\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mAIzaSyCTaWFK-kdtGNcZD06SgiMPmfV_1eGAuW8\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# Replace if needed\u001b[39;00m\n\u001b[32m      4\u001b[39m llm = ChatGoogleGenerativeAI(model=\u001b[33m\"\u001b[39m\u001b[33mgemini-2.5-flash\u001b[39m\u001b[33m\"\u001b[39m, temperature=\u001b[32m0.05\u001b[39m)\n\u001b[32m      6\u001b[39m prompt_template = ChatPromptTemplate.from_messages(\n\u001b[32m      7\u001b[39m     [\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m         \u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are an expert financial analyst. Your task is to extract various line items and their values from the provided text. \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m                   \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOutput the extracted data as a JSON array of objects, where each object has \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mitem_number\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m (if there is item number, or else leave blank),\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstatement_type\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mitem\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myear\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, and \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m. \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m                   \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEnsure values are numeric (remove commas, currency symbols, etc.) or leave empty if not found.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m                   \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEnsure that the line items, as well as the name of the statements are the same as the language being used in the text.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[43m                   \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSometimes there can be grammatial error and line item numering error, make sure to fix it as well, don\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mt be too rigid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m                   \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mONLY take the current year from this statement, not the last years.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     14\u001b[39m \u001b[43m                   \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMake sure that the line items are in proper form, that is no FULL CAPITALIZTATION, and only First Letter Capitalization\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[43m                   \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mThe name of the statements must be consistent and indifferent as given from the prompt.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhuman\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mExtract information from the 3 financial statements including: Income Statement, Balance Sheet, and Statement of Cash Flows, use the aforementioned categorey as the names for statement_type, do not put different names\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m :\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{text}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     ]\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m chain = prompt_template | llm | StrOutputParser()\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Starting LLM Extraction ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[31mTypeError\u001b[39m: 'tuple' object is not callable"
                    ]
                }
            ],
            "source": [
                "# Set API Key\n",
                "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCTaWFK-kdtGNcZD06SgiMPmfV_1eGAuW8\" # Replace if needed\n",
                "\n",
                "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.05)\n",
                "\n",
                "prompt_template = ChatPromptTemplate.from_messages(\n",
                "    [\n",
                "        (\"system\", \"You are an expert financial analyst. Your task is to extract various line items and their values from the provided text. \"\n",
                "                   \"Output the extracted data as a JSON array of objects, where each object has 'item_number' (if there is item number, or else leave blank),'statement_type', 'item', 'year', and 'value'. \"\n",
                "                   \"Ensure values are numeric (remove commas, currency symbols, etc.) or leave empty if not found.\"\n",
                "                   \"Ensure that the line items, as well as the name of the statements are the same as the language being used in the text.\"\n",
                "                   \"Sometimes there can be grammatial error and line item numering error, make sure to fix it as well, don't be too rigid\"\n",
                "                   \"ONLY take the current year from this statement, not the last years.\"\n",
                "                   \"Make sure that the line items are in proper form, that is no FULL CAPITALIZTATION, and only First Letter Capitalization\"\n",
                "                   \"The name of the statements must be consistent and indifferent as given from the prompt.\"),\n",
                "        (\"human\", \"Extract information from the 3 financial statements including: Income Statement, Balance Sheet, and Statement of Cash Flows, use the aforementioned categorey as the names for statement_type, do not put different names' :\\n\\n{text}\")\n",
                "    ]\n",
                ")\n",
                "\n",
                "chain = prompt_template | llm | StrOutputParser()\n",
                "\n",
                "print(\"--- Starting LLM Extraction ---\")\n",
                "for period in periods_to_process:\n",
                "    txt_file = text_dir / f\"{period}_{extraction_method}.txt\"\n",
                "    out_json = json_dir / f\"{period}_raw.json\"\n",
                "    \n",
                "    if not txt_file.exists():\n",
                "        print(f\"Skipping {period}: Text file not found.\")\n",
                "        continue\n",
                "        \n",
                "    print(f\"Invoking Gemini for {period}...\")\n",
                "    try:\n",
                "        with txt_file.open(\"r\", encoding=\"utf-8\") as f:\n",
                "            content = f.read()\n",
                "            \n",
                "        response = chain.invoke({\"text\": content})\n",
                "        with out_json.open(\"w\", encoding=\"utf-8\") as f:\n",
                "            f.write(response)\n",
                "        print(f\"Saved raw JSON to: {out_json.name}\")\n",
                "    except Exception as e:\n",
                "        print(f\"Error with LLM for {period}: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "excel_header",
            "metadata": {},
            "source": [
                "## 4. Excel Conversion"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "excel_logic",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Starting Excel Conversion ---\n",
                        "\n",
                        "Done!\n"
                    ]
                }
            ],
            "source": [
                "print(\"--- Starting Excel Conversion ---\")\n",
                "for period in periods_to_process:\n",
                "    json_file = json_dir / f\"{period}_raw.json\"\n",
                "    out_excel = excel_dir / f\"{period}_statements.xlsx\"\n",
                "    \n",
                "    if not json_file.exists():\n",
                "        continue\n",
                "        \n",
                "    try:\n",
                "        with json_file.open(\"r\", encoding=\"utf-8\") as f:\n",
                "            raw_data = f.read()\n",
                "        \n",
                "        # Clean JSON markdown blocks\n",
                "        clean_json = re.sub(r'^```json\\s*|\\s*```$', '', raw_data.strip(), flags=re.MULTILINE)\n",
                "        data = json.loads(clean_json)\n",
                "        \n",
                "        # Handle nested data if present\n",
                "        if isinstance(data, dict):\n",
                "            data = data.get(\"financial_statements\", data.get(\"data\", data))\n",
                "            \n",
                "        if isinstance(data, list):\n",
                "            df = pd.DataFrame(data)\n",
                "            if 'value' in df.columns:\n",
                "                df['value'] = pd.to_numeric(df['value'].astype(str).str.replace(',', '').str.strip(), errors='coerce')\n",
                "            \n",
                "            df.to_excel(out_excel, index=False)\n",
                "            print(f\"Converted {period} to Excel: {out_excel.name} ({len(df)} items)\")\n",
                "    except Exception as e:\n",
                "        print(f\"Error converting {period}: {e}\")\n",
                "\n",
                "print(\"\\nDone!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "generic",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
