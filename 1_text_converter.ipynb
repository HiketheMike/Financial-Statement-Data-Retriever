{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# Unified Financial Statement Data Retriever\n",
                "This notebook unifies the process of extracting data from financial statements (PDFs) using either OCR or Direct extraction methods, followed by LLM-based parsing and Excel conversion."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import io\n",
                "import json\n",
                "import re\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "from pypdf import PdfReader\n",
                "import pytesseract\n",
                "from PIL import Image\n",
                "from langchain_google_genai import ChatGoogleGenerativeAI\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_core.output_parsers import StrOutputParser"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "config_header",
            "metadata": {},
            "source": [
                "## 1. Configuration and User Input"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "id": "config",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Configured for: vital_farm\n",
                        "Periods: ['2020', '2021', '2022', '2023', '2024']\n",
                        "Method: PYPDF\n",
                        "Page range: 60-140\n"
                    ]
                }
            ],
            "source": [
                "# --- User Input ---\n",
                "company_folder_name = input(\"Enter the company folder name (e.g., PVIAM): \").strip()\n",
                "periods_input = input(\"Enter periods to process (e.g., 2021, 2022): \")\n",
                "periods_to_process = [p.strip() for p in periods_input.split(',') if p.strip()]\n",
                "\n",
                "extraction_method = \"\"\n",
                "while extraction_method not in [\"ocr\", \"pypdf\"]:\n",
                "    extraction_method = input(\"Choose extraction method (ocr / pypdf): \").strip().lower()\n",
                "\n",
                "page_range_input = input(\"Enter page range (e.g., 50-90, leave blank for all): \").strip()\n",
                "start_page, end_page = None, None\n",
                "if page_range_input and '-' in page_range_input:\n",
                "    try:\n",
                "        s, e = page_range_input.split('-')\n",
                "        start_page, end_page = int(s), int(e)\n",
                "    except ValueError:\n",
                "        print(\"Invalid range format. Processing all pages.\")\n",
                "\n",
                "# --- Paths ---\n",
                "# Updated to use the correct workspace root\n",
                "base_workspace = Path(r\"D:\\Visual Studio Projects\\Financial Statement Data Retriever\")\n",
                "company_base_path = base_workspace / company_folder_name\n",
                "base_pdf_dir = company_base_path / \"financial_statements\"\n",
                "text_dir = company_base_path / \"text_statements\"\n",
                "json_dir = company_base_path / \"json_statements\"\n",
                "excel_dir = company_base_path / \"excel_statements\"\n",
                "\n",
                "for d in [text_dir, json_dir, excel_dir]:\n",
                "    d.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(f\"\\nConfigured for: {company_folder_name}\")\n",
                "print(f\"Periods: {periods_to_process}\")\n",
                "print(f\"Method: {extraction_method.upper()}\")\n",
                "if start_page:\n",
                "    print(f\"Page range: {start_page}-{end_page}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "extraction_header",
            "metadata": {},
            "source": [
                "## 2. PDF to Text Extraction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "id": "extraction_logic",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Starting PDF Text Extraction ---\n",
                        "Processing 2020 via PYPDF...\n",
                        "Saved to: 2020_pypdf.txt\n",
                        "Processing 2021 via PYPDF...\n",
                        "Saved to: 2021_pypdf.txt\n",
                        "Processing 2022 via PYPDF...\n",
                        "Saved to: 2022_pypdf.txt\n",
                        "Processing 2023 via PYPDF...\n",
                        "Saved to: 2023_pypdf.txt\n",
                        "Processing 2024 via PYPDF...\n",
                        "Saved to: 2024_pypdf.txt\n"
                    ]
                }
            ],
            "source": [
                "def extract_text_from_pdf(pdf_path, method, start_page=None, end_page=None):\n",
                "    text_content = []\n",
                "    \n",
                "    if method == \"pypdf\":\n",
                "        reader = PdfReader(pdf_path)\n",
                "        total_pages = len(reader.pages)\n",
                "        pages_to_extract = range(total_pages)\n",
                "        if start_page and end_page:\n",
                "            pages_to_extract = range(max(0, start_page - 1), min(total_pages, end_page))\n",
                "            \n",
                "        for i in pages_to_extract:\n",
                "            page = reader.pages[i]\n",
                "            text = page.extract_text()\n",
                "            text_content.append(f\"--- PAGE {i+1} ---\\n{text}\\n\")\n",
                "            \n",
                "    else: # fitz or ocr\n",
                "        doc = fitz.open(pdf_path)\n",
                "        total_pages = len(doc)\n",
                "        pages_to_extract = range(total_pages)\n",
                "        if start_page and end_page:\n",
                "            pages_to_extract = range(max(0, start_page - 1), min(total_pages, end_page))\n",
                "\n",
                "        for i in pages_to_extract:\n",
                "            page = doc.load_page(i)\n",
                "            if method == \"ocr\":\n",
                "                pix = page.get_pixmap(dpi=300) # Balanced DPI\n",
                "                img_bytes = pix.tobytes(\"png\")\n",
                "                img = Image.open(io.BytesIO(img_bytes))\n",
                "                text = pytesseract.image_to_string(img, lang=\"vie+eng\", config=\"--psm 3\")\n",
                "            else: # direct fitz\n",
                "                text = page.get_text(\"text\")\n",
                "            \n",
                "            text_content.append(f\"--- PAGE {i+1} ---\\n{text}\\n\")\n",
                "        doc.close()\n",
                "        \n",
                "    return \"\\n\".join(text_content)\n",
                "\n",
                "print(\"--- Starting PDF Text Extraction ---\")\n",
                "for period in periods_to_process:\n",
                "    pdf_path = base_pdf_dir / f\"{period}.pdf\"\n",
                "    out_txt = text_dir / f\"{period}_{extraction_method}.txt\"\n",
                "    \n",
                "    if not pdf_path.exists():\n",
                "        print(f\"Skipping {period}: File not found at {pdf_path}\")\n",
                "        continue\n",
                "        \n",
                "    print(f\"Processing {period} via {extraction_method.upper()}...\")\n",
                "    try:\n",
                "        extracted_text = extract_text_from_pdf(pdf_path, extraction_method, start_page, end_page)\n",
                "        with out_txt.open(\"w\", encoding=\"utf-8\") as f:\n",
                "            f.write(extracted_text)\n",
                "        print(f\"Saved to: {out_txt.name}\")\n",
                "    except Exception as e:\n",
                "        print(f\"Error processing {period}: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "llm_header",
            "metadata": {},
            "source": [
                "## 3. LLM Data Extraction (Gemini)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "id": "llm_logic",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Starting LLM Extraction ---\n",
                        "Invoking Gemini for 2020...\n",
                        "Saved raw JSON to: 2020_raw.json\n",
                        "Invoking Gemini for 2021...\n",
                        "Saved raw JSON to: 2021_raw.json\n",
                        "Invoking Gemini for 2022...\n",
                        "Saved raw JSON to: 2022_raw.json\n",
                        "Invoking Gemini for 2023...\n",
                        "Saved raw JSON to: 2023_raw.json\n",
                        "Invoking Gemini for 2024...\n",
                        "Saved raw JSON to: 2024_raw.json\n"
                    ]
                }
            ],
            "source": [
                "# Set API Key\n",
                "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAl51JWsEN4RTPa0gaoCVtNsOuPfaxtHRQ\" # Replace if needed\n",
                "\n",
                "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.05)\n",
                "\n",
                "prompt_template = ChatPromptTemplate.from_messages(\n",
                "    [\n",
                "        (\"system\", \"You are an expert financial analyst. Your task is to extract various line items and their values from the provided text. \"\n",
                "                   \"Output the extracted data as a JSON array of objects, where each object has 'item_number' (if there is item number, or else leave blank),'statement_type', 'item', 'year', and 'value'. \"\n",
                "                   \"Ensure values are numeric (remove commas, currency symbols, etc.) or leave empty if not found.\"\n",
                "                   \"Ensure that the line items, as well as the name of the statements are the same as the language being used in the text.\"\n",
                "                   \"Sometimes there can be grammatial error and line item numering error, make sure to fix it as well, don't be too rigid\"\n",
                "                   \"ONLY take the current year from this statement, not the last years.\"\n",
                "                   \"Make sure that the line items are in proper form, that is no FULL CAPITALIZTATION, and only First Letter Capitalization\"\n",
                "                   \"The name of the statements must be consistent and indifferent as given from the prompt.\"),\n",
                "        (\"human\", \"Extract information from the 3 financial statements including: Income Statement, Balance Sheet, and Statement of Cash Flows, use the aforementioned categorey as the names for statement_type, do not put different names' :\\n\\n{text}\")\n",
                "    ]\n",
                ")\n",
                "\n",
                "chain = prompt_template | llm | StrOutputParser()\n",
                "\n",
                "print(\"--- Starting LLM Extraction ---\")\n",
                "for period in periods_to_process:\n",
                "    txt_file = text_dir / f\"{period}_{extraction_method}.txt\"\n",
                "    out_json = json_dir / f\"{period}_raw.json\"\n",
                "    \n",
                "    if not txt_file.exists():\n",
                "        print(f\"Skipping {period}: Text file not found.\")\n",
                "        continue\n",
                "        \n",
                "    print(f\"Invoking Gemini for {period}...\")\n",
                "    try:\n",
                "        with txt_file.open(\"r\", encoding=\"utf-8\") as f:\n",
                "            content = f.read()\n",
                "            \n",
                "        response = chain.invoke({\"text\": content})\n",
                "        with out_json.open(\"w\", encoding=\"utf-8\") as f:\n",
                "            f.write(response)\n",
                "        print(f\"Saved raw JSON to: {out_json.name}\")\n",
                "    except Exception as e:\n",
                "        print(f\"Error with LLM for {period}: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "excel_header",
            "metadata": {},
            "source": [
                "## 4. Excel Conversion"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "id": "excel_logic",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Starting Excel Conversion ---\n",
                        "Converted 2020 to Excel: 2020_statements.xlsx (102 items)\n",
                        "Converted 2021 to Excel: 2021_statements.xlsx (99 items)\n",
                        "Converted 2022 to Excel: 2022_statements.xlsx (93 items)\n",
                        "Converted 2023 to Excel: 2023_statements.xlsx (90 items)\n",
                        "Converted 2024 to Excel: 2024_statements.xlsx (93 items)\n",
                        "\n",
                        "Done!\n"
                    ]
                }
            ],
            "source": [
                "print(\"--- Starting Excel Conversion ---\")\n",
                "for period in periods_to_process:\n",
                "    json_file = json_dir / f\"{period}_raw.json\"\n",
                "    out_excel = excel_dir / f\"{period}_statements.xlsx\"\n",
                "    \n",
                "    if not json_file.exists():\n",
                "        continue\n",
                "        \n",
                "    try:\n",
                "        with json_file.open(\"r\", encoding=\"utf-8\") as f:\n",
                "            raw_data = f.read()\n",
                "        \n",
                "        # Clean JSON markdown blocks\n",
                "        clean_json = re.sub(r'^```json\\s*|\\s*```$', '', raw_data.strip(), flags=re.MULTILINE)\n",
                "        data = json.loads(clean_json)\n",
                "        \n",
                "        # Handle nested data if present\n",
                "        if isinstance(data, dict):\n",
                "            data = data.get(\"financial_statements\", data.get(\"data\", data))\n",
                "            \n",
                "        if isinstance(data, list):\n",
                "            df = pd.DataFrame(data)\n",
                "            if 'value' in df.columns:\n",
                "                df['value'] = pd.to_numeric(df['value'].astype(str).str.replace(',', '').str.strip(), errors='coerce')\n",
                "            \n",
                "            df.to_excel(out_excel, index=False)\n",
                "            print(f\"Converted {period} to Excel: {out_excel.name} ({len(df)} items)\")\n",
                "    except Exception as e:\n",
                "        print(f\"Error converting {period}: {e}\")\n",
                "\n",
                "print(\"\\nDone!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "generic",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
