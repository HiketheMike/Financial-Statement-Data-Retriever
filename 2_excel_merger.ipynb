{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "799344e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company folder set to: CALM\n",
      "Periods set for processing: ['2020', '2021', '2022', '2023', '2024', '2025']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# --- User Input for Company Folder ---\n",
    "company_folder_name = input(\"Enter the company folder name (e.g., PVIAM): \").strip()\n",
    "\n",
    "if not company_folder_name:\n",
    "    print(\"No company folder name entered. Please run this cell again and provide a name.\")\n",
    "else:\n",
    "    print(f\"Company folder set to: {company_folder_name}\")\n",
    "\n",
    "company_base_path = Path(r\"D:\\Visual Studio Projects\\Financial Statement Data Retriever\") / company_folder_name\n",
    "\n",
    "# --- User Input for Year Range ---\n",
    "try:\n",
    "    start_year = int(input(\"Enter start year (e.g., 2021): \").strip())\n",
    "    end_year = int(input(\"Enter end year (e.g., 2024): \").strip())\n",
    "    \n",
    "    # Generate list of years as strings from start to end (inclusive)\n",
    "    periods_to_process = [str(year) for year in range(start_year, end_year + 1)]\n",
    "    \n",
    "    if not periods_to_process:\n",
    "        print(\"No periods generated. Please check if the start year is less than or equal to the end year.\")\n",
    "    else:\n",
    "        print(f\"Periods set for processing: {periods_to_process}\")\n",
    "except ValueError:\n",
    "    print(\"Invalid input. Please enter numeric values for years.\")\n",
    "    periods_to_process = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2e3f02",
   "metadata": {},
   "source": [
    "## <span style = 'color:blue'> Merging excel Files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43729c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read in 6 years of financial statements in Excel \n",
      "\n",
      "=============================== BEGINNING CONCATENATING EACH PERIODS =============================== \n",
      "1) SUCCESS: Concatenated successfully dataframes from all periods. Total rows: 545\n",
      "Applied proper casing to 'statement_type' column.\n",
      "\n",
      "--- Saving Full Concatenated DataFrame ---\n",
      "Successfully saved full concatenated DataFrame to: D:\\Visual Studio Projects\\Financial Statement Data Retriever\\CALM\\period_statements\\all_periods_concatenated.xlsx\n",
      "------------------------------------------\n",
      "\n",
      "============================= SEPARATING BY STATEMENT TYPE AND SAVING ============================== \n",
      "Found 3 unique statement types: Income Statement, Balance Sheet, Statement Of Cash Flows\n",
      "  - Successfully saved 'Income Statement' to: D:\\Visual Studio Projects\\Financial Statement Data Retriever\\CALM\\period_statements\\Income Statement.xlsx\n",
      "  - Successfully saved 'Balance Sheet' to: D:\\Visual Studio Projects\\Financial Statement Data Retriever\\CALM\\period_statements\\Balance Sheet.xlsx\n",
      "  - Successfully saved 'Statement Of Cash Flows' to: D:\\Visual Studio Projects\\Financial Statement Data Retriever\\CALM\\period_statements\\Statement Of Cash Flows.xlsx\n",
      "\n",
      "--- Statement Separation and Saving Complete ---\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Use the dynamically set company_base_path\n",
    "base_dir = company_base_path / \"excel_statements\"\n",
    "period_statements_dir = company_base_path / \"period_statements\"\n",
    "\n",
    "# Ensure the period_statements directory exists\n",
    "period_statements_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Read in the datasets\n",
    "financial_statements = []\n",
    "found_files_count = 0\n",
    "for period in periods_to_process:\n",
    "    statement_path = base_dir / f\"{period}_statements.xlsx\"\n",
    "    if not statement_path.exists():\n",
    "        print(f'Warning: Excel file not found for period {period} at {statement_path}. Skipping this period.')\n",
    "        continue\n",
    "    try:\n",
    "        df_statement = pd.read_excel(statement_path)\n",
    "        financial_statements.append(df_statement)\n",
    "        found_files_count += 1\n",
    "    except Exception as e:\n",
    "        print(f'Error reading {statement_path}: {e}. Skipping this period.')\n",
    "        continue\n",
    "\n",
    "if found_files_count > 0:\n",
    "    print(f'Successfully read in {found_files_count} years of financial statements in Excel \\n')\n",
    "else: \n",
    "    print(f'No financial statements were successfully read from Excel files. Please check paths and file existence.')\n",
    "    # Exit or handle the case where no data is loaded\n",
    "    # For now, we'll proceed, but concatenated_df will be empty if financial_statements is empty.\n",
    "\n",
    "\n",
    "# Begin merging the datasets together based on criteria\n",
    "print(f\"{f' BEGINNING CONCATENATING EACH PERIODS ':=^100} \")\n",
    "row_length = 0\n",
    "for df_statement in financial_statements:\n",
    "    row_length += len(df_statement)\n",
    "\n",
    "if financial_statements: # Only concatenate if there's data to concatenate\n",
    "    concatenated_df = pd.concat(financial_statements, ignore_index=True)\n",
    "\n",
    "    if len(concatenated_df) == row_length:\n",
    "        print(f'1) SUCCESS: Concatenated successfully dataframes from all periods. Total rows: {len(concatenated_df)}')\n",
    "    else:\n",
    "        print(f'1) ERROR: There are missing rows or an issue during concatenation. Expected {row_length} rows, got {len(concatenated_df)}.')\n",
    "\n",
    "    # --- New: Apply proper casing to 'statement_type' column ---\n",
    "    if 'statement_type' in concatenated_df.columns:\n",
    "        concatenated_df['statement_type'] = concatenated_df['statement_type'].astype(str).str.title()\n",
    "        print(\"Applied proper casing to 'statement_type' column.\")\n",
    "    # --- End New ---\n",
    "\n",
    "    # --- New Logic: Save the full concatenated_df to Excel ---\n",
    "    print(\"\\n--- Saving Full Concatenated DataFrame ---\")\n",
    "    full_concatenated_output_path = period_statements_dir / \"all_periods_concatenated.xlsx\"\n",
    "    try:\n",
    "        concatenated_df.to_excel(full_concatenated_output_path, index=False)\n",
    "        print(f\"Successfully saved full concatenated DataFrame to: {full_concatenated_output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not save full concatenated DataFrame: {e}\")\n",
    "    print(\"------------------------------------------\")\n",
    "    # --- End New Logic ---\n",
    "\n",
    "    # --- New Logic: Separate by statement_type and save to individual Excel files ---\n",
    "    print(f\"\\n{f' SEPARATING BY STATEMENT TYPE AND SAVING ':=^100} \")\n",
    "    \n",
    "    unique_statement_types = concatenated_df['statement_type'].unique()\n",
    "    \n",
    "    if len(unique_statement_types) > 0:\n",
    "        print(f\"Found {len(unique_statement_types)} unique statement types: {', '.join(unique_statement_types)}\")\n",
    "        for st_type in unique_statement_types:\n",
    "            # Filter the concatenated DataFrame for the current statement type\n",
    "            df_filtered = concatenated_df[concatenated_df['statement_type'] == st_type].copy()\n",
    "            \n",
    "            # Define the output path for the individual statement type Excel file\n",
    "            output_file_path = period_statements_dir / f\"{st_type}.xlsx\"\n",
    "            \n",
    "            # Save to Excel\n",
    "            try:\n",
    "                df_filtered.to_excel(output_file_path, index=False)\n",
    "                print(f\"  - Successfully saved '{st_type}' to: {output_file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  - ERROR: Could not save '{st_type}' to {output_file_path}: {e}\")\n",
    "    else:\n",
    "        print(\"No unique 'statement_type' found in the concatenated data. No individual files created.\")\n",
    "\n",
    "    print(\"\\n--- Statement Separation and Saving Complete ---\")\n",
    "\n",
    "else:\n",
    "    print(\"No dataframes were available for concatenation. Skipping separation by statement type.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
